{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebooks gathers and cleans dataframes for vehicle registrations, population, GDP, GDP by industry, C02 emissions and energy consumption. \n",
    "\n",
    "### The goal is to get all these dataframes in the same format, so we can use them to create a multiple linear regression model. Once we have all the dataframes cleaned and in the correct format, we will write them out, so that the cleaned dataframes can be used for analysis. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Gathering\n",
    "#### This section of the notebooks reads in the data files and stores them im pandas dataframes.\n",
    "The dataframes frames in this section all have columns of represting years ranging from [1967-2020] and rows for each state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join(os.getcwd(), \"Data/uncleaned/csv\")\n",
    "excel_path = os.path.join(os.getcwd(), \"Data/uncleaned/excel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in all datasets here \n",
    "\n",
    "vehicle_registration_df = pd.read_csv(os.path.join(csv_path, \"vehicle_registrations_by_state.csv\"))\n",
    "energy_consumption_per_real_gdp_df = pd.read_csv(os.path.join(csv_path, \"energy_consumption_per_real_gdp.csv\"))\n",
    "current_dollar_gdp_df = pd.read_csv(os.path.join(csv_path, \"Current_dollar_GDP.csv\")) #in millions\n",
    "total_consuption_df = pd.read_csv(os.path.join(csv_path, \"total_consuption.csv\")) #in billion Btu\n",
    "industy_gdp_by_state_df = pd.read_csv(os.path.join(csv_path, \"industy_gdp_by_state.csv\"))\n",
    "total_population_df = pd.read_csv(os.path.join(csv_path, \"total_population.csv\"))\n",
    "real_gdp_df = pd.read_csv(os.path.join(csv_path, \"real_GDP.csv\")) #in millions\n",
    "ghg_emissions_df = pd.read_csv(os.path.join(csv_path, \"GHG_Emissions.csv\"))\n",
    "co2_emissions_df = pd.read_excel(os.path.join(excel_path, \"co2_emissions.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_names=[\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \"Connecticut\", \"Delaware\", \"Florida\", \"Georgia\", \"Hawaii\", \"Idaho\", \"Illinois\", \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Maine\", \"Maryland\", \"Massachusetts\", \"Michigan\", \"Minnesota\", \"Mississippi\", \"Missouri\", \"Montana\", \"Nebraska\", \"Nevada\", \"New Hampshire\", \"New Jersey\", \"New Mexico\", \"New York\", \"North Carolina\", \"North Dakota\", \"Ohio\", \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"Rhode Island\", \"South Carolina\", \"South Dakota\", \"Tennessee\", \"Texas\", \"Utah\", \"Vermont\", \"Virginia\", \"Washington\", \"West Virginia\", \"Wisconsin\", \"Wyoming\"]\n",
    "state_abbreviations = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\", \n",
    "          \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "          \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "          \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
    "          \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnamed_columns_to_drop = ['Unnamed: 91', 'Unnamed: 92', 'Unnamed: 93', 'Unnamed: 94',\n",
    "       'Unnamed: 95', 'Unnamed: 96', 'Unnamed: 97', 'Unnamed: 98',\n",
    "       'Unnamed: 99', 'Unnamed: 100','Unnamed: 62', 'Unnamed: 63', 'Unnamed: 64', 'Unnamed: 65',\n",
    "       'Unnamed: 66', 'Unnamed: 67', 'Unnamed: 68', 'Unnamed: 69',\n",
    "       'Unnamed: 70', 'Unnamed: 71', 'Unnamed: 72', 'Unnamed: 73',\n",
    "       'Unnamed: 74', 'Unnamed: 75', 'Unnamed: 76', 'Unnamed: 77',\n",
    "       'Unnamed: 78', 'Unnamed: 79', 'Unnamed: 80', 'Unnamed: 81',\n",
    "       'Unnamed: 82', 'Unnamed: 83', 'Unnamed: 84', 'Unnamed: 85',\n",
    "       'Unnamed: 86', 'Unnamed: 87', 'Unnamed: 88', 'Unnamed: 89',\n",
    "       'Unnamed: 90', 'Unnamed: 61', 'Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe(df):\n",
    "    srings_to_replace = [\"(NA)\", \"(L)\", \"(D)\", \"Change\", \"(2000â€“2018)\", \"Percent\", \"Absolute\"]\n",
    "    unnamed_to_drop = list(set(df.columns).intersection(unnamed_columns_to_drop))\n",
    "    df = df.drop(columns = unnamed_to_drop)\n",
    "    \n",
    "    null_values_allowed_before_column_is_dropped = 40\n",
    "    columns_to_drop = []\n",
    "    first_col = df.columns[0]\n",
    "    for index, row in df.iterrows():\n",
    "        df.at[index, first_col] = str(df.at[index, first_col]).replace(\"(Items)\", \"\").strip()\n",
    "\n",
    "    for col in df.columns[1:]:\n",
    "        df.loc[df[col].isin(srings_to_replace), col] = np.nan\n",
    "        df[col] = df[col].astype(float)\n",
    "        \n",
    "        if(df[col].isna().sum() > null_values_allowed_before_column_is_dropped):\n",
    "            columns_to_drop.append(col)\n",
    "        else:\n",
    "            df[col].fillna(value=pd.to_numeric(df[col], errors='coerce').mean(), inplace=True)\n",
    "    df = df.drop( columns = columns_to_drop)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join(os.getcwd(), \"Data/cleaned/csv\")\n",
    "excel_path = os.path.join(os.getcwd(), \"Data/cleaned/excel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/DYTS.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/HTDD.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/TMAX.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/HX01.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/DSNW.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/DT32.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/EMXT.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/EMXP.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/DSND.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/EVAP.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/PSUN.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/DP1X.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/MNPN.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/EMSD.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/HDSD.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/PRCP.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/TSUN.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/WSF5.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/WSFG.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/LX01.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/DX70.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/WSF2.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/DYFG.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/TMIN.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/CLDD.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/WDF2.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/CDSD.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/EMSN.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/WDFG.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/WDF5.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/DYHF.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/DX90.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/SNOW.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/WDMV.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/DP01.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/EMNT.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/DX32.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/MXPN.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/TAVG.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/DP10.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/MX01.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/AWND.csv\n",
      "/Users/haleyhartin/Projects/State-Of-The-Energy/Data/cleaned/csv/NOA/DT00.csv\n"
     ]
    }
   ],
   "source": [
    "#read in and clean all the NOA files\n",
    "files = os.listdir(os.path.join(os.getcwd(), \"Data/uncleaned/csv/NOA\"))\n",
    "for file in files:\n",
    "    if(\".csv\" in file):\n",
    "        print(os.path.join(csv_path,'NOA', file))\n",
    "        df = pd.read_csv(os.path.join(os.getcwd(), \"Data/uncleaned/csv/NOA\", file), index_col=None)\n",
    "        df = clean_dataframe(df)\n",
    "        df.to_csv(os.path.join(csv_path,'NOA', file))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_registration_df.drop(index = [0,1,2,3,4,5,6,7,8,9,61,62,64,63], inplace = True)\n",
    "vehicle_registration_df = clean_dataframe(vehicle_registration_df)\n",
    "vehicle_registration_df =  vehicle_registration_df[vehicle_registration_df['Years'].isin(state_names)]\n",
    "vehicle_registration_columns = vehicle_registration_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_population_df = clean_dataframe(total_population_df)\n",
    "total_population_df =  total_population_df[total_population_df['State'].isin(state_abbreviations)]\n",
    "total_population_columns = total_population_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_consuption_df = clean_dataframe(total_consuption_df)\n",
    "total_consuption_df =  total_consuption_df[total_consuption_df['State'].isin(state_abbreviations)]\n",
    "total_consuption_df_columns = total_consuption_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_gdp_df = clean_dataframe(real_gdp_df)\n",
    "real_gdp_df =  real_gdp_df[real_gdp_df['State'].isin(state_abbreviations)]\n",
    "real_gdp_df_columns = real_gdp_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "industy_gdp_by_state_df = industy_gdp_by_state_df.drop(columns = ['GeoFIPS','Region','TableName','LineCode','IndustryClassification','Description','Unit'])\n",
    "industy_gdp_by_state_df = clean_dataframe(industy_gdp_by_state_df)\n",
    "industy_gdp_by_state_df = industy_gdp_by_state_df.groupby('GeoName').mean().reset_index()\n",
    "industy_gdp_by_state_df =  industy_gdp_by_state_df[industy_gdp_by_state_df['GeoName'].isin(state_names)]\n",
    "industy_gdp_by_state_df_columns = industy_gdp_by_state_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co2_emissions_df = co2_emissions_df.rename({'Table 2. State energy-related carbon dioxide emissions by year, adjusted (2000â€“2018)': 'State', 'Unnamed: 1': '2000', 'Unnamed: 2': '2001', 'Unnamed: 3': '2002', 'Unnamed: 4': '2003', 'Unnamed: 5': '2004',\n",
    "       'Unnamed: 6': '2005', 'Unnamed: 7': '2006', 'Unnamed: 8': '2007', 'Unnamed: 9': '2008', 'Unnamed: 10': '2009',\n",
    "       'Unnamed: 11': '2010', 'Unnamed: 12': '2011', 'Unnamed: 13': '2012', 'Unnamed: 14': '2013',\n",
    "       'Unnamed: 15': '2014', 'Unnamed: 16': '2015', 'Unnamed: 17': '2016', 'Unnamed: 18': '2017',\n",
    "       'Unnamed: 19': '2018', 'Unnamed: 20': '2019', 'Unnamed: 21': '2020'}, axis =1).reset_index()\n",
    "co2_emissions_df = co2_emissions_df.drop(columns = ['index'])\n",
    "co2_emissions_df =  co2_emissions_df[co2_emissions_df['State'].isin(state_names)]\n",
    "co2_emissions_df_columns = co2_emissions_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide GDP and industry GDP by cooresponding population values to normalize population for the regression\n",
    "columns_to_evaluate = list(set(real_gdp_df.columns).intersection(industy_gdp_by_state_df.columns).intersection(total_population_df.columns))\n",
    "\n",
    "for col in columns_to_evaluate:\n",
    "    for i in range(0,50):\n",
    "        population = total_population_df.iloc[i][col]\n",
    "        if(population > 0):\n",
    "            real_gdp_df.iloc[i][col] = real_gdp_df.iloc[i][col] / population\n",
    "            industy_gdp_by_state_df.iloc[i][col] = industy_gdp_by_state_df.iloc[i][col] / population\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the data out to new files\n",
    "#### This section of the notebooks writes the cleaned dataframes out into new files that can be used by other notebooks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_registration_df.to_csv(os.path.join(csv_path, \"vehicle_registrations_by_state.csv\"))\n",
    "energy_consumption_per_real_gdp_df.to_csv(os.path.join(csv_path, \"energy_consumption_per_real_gdp.csv\"))\n",
    "current_dollar_gdp_df.to_csv(os.path.join(csv_path, \"Current_dollar_GDP.csv\")) #in millions\n",
    "total_consuption_df.to_csv(os.path.join(csv_path, \"total_consuption.csv\")) #in billion Btu\n",
    "industy_gdp_by_state_df.to_csv(os.path.join(csv_path, \"industy_gdp_by_state.csv\"))\n",
    "total_population_df.to_csv(os.path.join(csv_path, \"total_population.csv\"))\n",
    "real_gdp_df.to_csv(os.path.join(csv_path, \"real_GDP.csv\")) #in millions\n",
    "co2_emissions_df.to_excel(os.path.join(excel_path, \"co2_emissions.xlsx\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
