{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Gathering\n",
    "#### This section of the notebooks reads in the data files and stores them im pandas dataframes.\n",
    "The dataframes frames in this section all have colums of [1960 - 2019] and rows for each state execpt for industy_gdp_by_state_df which goes from [1997-2020] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join(os.getcwd(), \"data/csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in all datasets here \n",
    "\n",
    "vehicle_registration_df = pd.read_csv(os.path.join(csv_path, \"vehicle_registrations_by_state.csv\"))\n",
    "energy_consumption_per_real_gdp_df = pd.read_csv(os.path.join(csv_path, \"energy_consumption_per_real_gdp.csv\"))\n",
    "current_dollar_gdp_df = pd.read_csv(os.path.join(csv_path, \"Current_dollar_GDP.csv\")) #in millions\n",
    "total_consuption_df = pd.read_csv(os.path.join(csv_path, \"total_consuption.csv\")) #in billion Btu\n",
    "industy_gdp_by_state_df = pd.read_csv(os.path.join(csv_path, \"industy_gdp_by_state.csv\"))\n",
    "total_population_df = pd.read_csv(os.path.join(csv_path, \"total_population.csv\"))\n",
    "real_gdp_df = pd.read_csv(os.path.join(csv_path, \"real_GDP.csv\")) #in millions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "#### This section of the notebook cleans the data frames. \n",
    "\n",
    "We start by dropping all the unneeded columns so that each data frame has the same colums. Then we drop any columns that have missing values. This only leaves us with a few columns, so it might be a better idea in the future to replace empty values with the mean value for that year or something similar. \n",
    "\n",
    "This section is only evaluting vehicle registration, and population against energy consuption as a proof of concept. We will need to clean and add all the other dataframes to this model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Unnamed: 91', 'Unnamed: 92', 'Unnamed: 93', 'Unnamed: 94',\n",
    "       'Unnamed: 95', 'Unnamed: 96', 'Unnamed: 97', 'Unnamed: 98',\n",
    "       'Unnamed: 99', 'Unnamed: 100','Unnamed: 62', 'Unnamed: 63', 'Unnamed: 64', 'Unnamed: 65',\n",
    "       'Unnamed: 66', 'Unnamed: 67', 'Unnamed: 68', 'Unnamed: 69',\n",
    "       'Unnamed: 70', 'Unnamed: 71', 'Unnamed: 72', 'Unnamed: 73',\n",
    "       'Unnamed: 74', 'Unnamed: 75', 'Unnamed: 76', 'Unnamed: 77',\n",
    "       'Unnamed: 78', 'Unnamed: 79', 'Unnamed: 80', 'Unnamed: 81',\n",
    "       'Unnamed: 82', 'Unnamed: 83', 'Unnamed: 84', 'Unnamed: 85',\n",
    "       'Unnamed: 86', 'Unnamed: 87', 'Unnamed: 88', 'Unnamed: 89',\n",
    "       'Unnamed: 90', 'Unnamed: 61']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_registration_df.drop(index = [0,1,2,3,4,5,6,7,8,9,61,62,64,63], inplace = True)\n",
    "vehicle_registration_df = vehicle_registration_df.dropna(axis='columns')\n",
    "vehicle_registration_df.head()\n",
    "vehicle_registration_columns = vehicle_registration_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_population_df.drop(index = [51], inplace = True)\n",
    "total_population_df = total_population_df.drop( columns = columns_to_drop)\n",
    "total_population_df = total_population_df.dropna(axis='columns')\n",
    "total_population_columns = total_population_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_consuption_df.drop(index = [51], inplace = True)\n",
    "total_consuption_df = total_consuption_df.drop( columns = columns_to_drop)\n",
    "total_consuption_df = total_consuption_df.dropna(axis='columns')\n",
    "total_consuption_df_columns = total_consuption_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the columns that are in each dataframe after columns with empty values have been dropped. \n",
    "columns_to_evaluate = list(set(vehicle_registration_columns).intersection(total_population_columns).intersection(total_consuption_df_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year 2010 length for vechical registration: 51\n",
      "year 2010 length for energy consumption: 51\n",
      "year 2010 length for population: 51\n",
      "\n",
      "year 2007 length for vechical registration: 51\n",
      "year 2007 length for energy consumption: 51\n",
      "year 2007 length for population: 51\n",
      "\n",
      "year 2018 length for vechical registration: 51\n",
      "year 2018 length for energy consumption: 51\n",
      "year 2018 length for population: 51\n",
      "\n",
      "year 2009 length for vechical registration: 51\n",
      "year 2009 length for energy consumption: 51\n",
      "year 2009 length for population: 51\n",
      "\n",
      "year 2008 length for vechical registration: 51\n",
      "year 2008 length for energy consumption: 51\n",
      "year 2008 length for population: 51\n",
      "\n",
      "year 2019 length for vechical registration: 51\n",
      "year 2019 length for energy consumption: 51\n",
      "year 2019 length for population: 51\n",
      "\n",
      "year 1998 length for vechical registration: 51\n",
      "year 1998 length for energy consumption: 51\n",
      "year 1998 length for population: 51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ensure each column we are going to evaluate has the same number of values \n",
    "for col in columns_to_evaluate:\n",
    "    print(\"year\" , col , \"length for vechical registration:\" , len(vehicle_registration_df[col]))\n",
    "    print(\"year\" , col , \"length for energy consumption:\" , len(total_consuption_df[col]))\n",
    "    print(\"year\" , col , \"length for population:\" , len(total_population_df[col]))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the data frames and add each value to data_point_pairs array. \n",
    "# The data_point_pairs array will be the [vehicle registration, population] value for each year and each state\n",
    "# The total_consumption_vals will be the cooresponding energy consuption value \n",
    "# for the [vehicle registration, population] data point\n",
    "data_point_pairs = []\n",
    "total_consumption_vals = []\n",
    "for col in columns_to_evaluate:\n",
    "    for i in range(0,51):\n",
    "        pair = [vehicle_registration_df.iloc[i][col], total_population_df.iloc[i][col]]\n",
    "        data_point_pairs.append(pair)\n",
    "        \n",
    "        total_consumption_vals.append(total_consuption_df.iloc[i][col]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vehicle registration: 4653838.0\n",
      "population:  714\n",
      "total energy consuption: 640590\n"
     ]
    }
   ],
   "source": [
    "print(\"vehicle registration:\" , data_point_pairs[0][0])\n",
    "print(\"population: \", data_point_pairs[0][1])\n",
    "print(\"total energy consuption:\" ,total_consumption_vals[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis\n",
    "\n",
    "#### This section of the notebooks creates a linear regression moel for energy consuption.\n",
    "\n",
    "Right now, the model is only using population and vehicle registration to predict energy comnsuption. We will need to include the other dataframes.\n",
    "\n",
    "In the model summary, x1 represents vehicle regisration and x2 represents population. There are some other values in the summary that give us a good indication as to how well our model fits energy consuption such at the r squared value and F statistic.\n",
    "\n",
    "We will have to look into why the coefficient for x2 is 291. It should be between (-1,1), so something is throwing the model off. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted energy consumpion for vehicle registration = 400000 , population =  800 (million): [542276.34089566]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.873</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.872</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   1216.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 23 Oct 2021</td> <th>  Prob (F-statistic):</th>          <td>1.38e-159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:19:53</td>     <th>  Log-Likelihood:    </th>          <td> -5441.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   357</td>      <th>  AIC:               </th>          <td>1.089e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   355</td>      <th>  BIC:               </th>          <td>1.090e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td>    0.0006</td> <td>    0.014</td> <td>    0.045</td> <td> 0.964</td> <td>   -0.026</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th> <td>  291.2033</td> <td>   10.900</td> <td>   26.717</td> <td> 0.000</td> <td>  269.767</td> <td>  312.639</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>196.037</td> <th>  Durbin-Watson:     </th> <td>   1.829</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2908.640</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.942</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.433</td>  <th>  Cond. No.          </th> <td>1.49e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.49e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      y   R-squared (uncentered):                   0.873\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.872\n",
       "Method:                 Least Squares   F-statistic:                              1216.\n",
       "Date:                Sat, 23 Oct 2021   Prob (F-statistic):                   1.38e-159\n",
       "Time:                        13:19:53   Log-Likelihood:                         -5441.9\n",
       "No. Observations:                 357   AIC:                                  1.089e+04\n",
       "Df Residuals:                     355   BIC:                                  1.090e+04\n",
       "Df Model:                           2                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1             0.0006      0.014      0.045      0.964      -0.026       0.027\n",
       "x2           291.2033     10.900     26.717      0.000     269.767     312.639\n",
       "==============================================================================\n",
       "Omnibus:                      196.037   Durbin-Watson:                   1.829\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2908.640\n",
       "Skew:                           1.942   Prob(JB):                         0.00\n",
       "Kurtosis:                      16.433   Cond. No.                     1.49e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.49e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A potential library we can use for regression analysis \n",
    "\n",
    "X = data_point_pairs\n",
    "y = total_consumption_vals\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X,y)\n",
    "\n",
    "#predict energy consuption for vehicle registration = 400000 , population =  800 (million)\n",
    "predictions = lm.predict([[400000, 800]])\n",
    "print(\"Predicted energy consumpion for vehicle registration = 400000 , population =  800 (million):\", predictions )\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "model.summary()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
