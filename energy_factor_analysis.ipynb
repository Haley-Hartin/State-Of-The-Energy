{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebooks explores the relationship between a state's number of vehicle registrations, population, GDP per capita, GDP per capita by industry,  C02 emissions, average yearly tempature, average yearly windspeed, minimum yearly tempature, maximim yearly tempature, total yearly precipitation , and total yearly snowfall on it's energy consumption. \n",
    "\n",
    "### The goal is to model a US state's energy consuption by using the data listed above. With this model we can make energy consuption predictions and understand what leads to high energy consuption.\n",
    "\n",
    "### The contents of the notebook include\n",
    "- #### Data Gathering\n",
    "    - read in the dataframes that have been cleaned by data_gathering_and_cleaning notebook\n",
    "- #### Data analysis \n",
    "    - create a multiple linear regression model for energy consuption\n",
    "- #### Conclusion\n",
    "    - Discuss what we discovered and draw conclusions\n",
    "    \n",
    "Note: If there are no files in the Data/cleaned diretory, you will need to run the 'data_gathering_and_cleaning\" notebook to clwan and write out the files to that directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Gathering\n",
    "#### This section of the notebooks reads in the data files and stores them im pandas dataframes.\n",
    "The dataframes frames in this section all have columns of represting years ranging from [1967-2020] and rows for each state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join(os.getcwd(), \"data/cleaned/csv\")\n",
    "excel_path = os.path.join(os.getcwd(), \"data/cleaned/excel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in all datasets here \n",
    "vehicle_registration_df = pd.read_csv(os.path.join(csv_path, \"vehicle_registrations_by_state.csv\"))\n",
    "energy_consumption_per_real_gdp_df = pd.read_csv(os.path.join(csv_path, \"energy_consumption_per_real_gdp.csv\"))\n",
    "current_dollar_gdp_df = pd.read_csv(os.path.join(csv_path, \"Current_dollar_GDP.csv\")) #in millions\n",
    "total_consuption_df = pd.read_csv(os.path.join(csv_path, \"total_consuption.csv\")) #in billion Btu\n",
    "industy_gdp_by_state_df = pd.read_csv(os.path.join(csv_path, \"industy_gdp_by_state.csv\"))\n",
    "total_population_df = pd.read_csv(os.path.join(csv_path, \"total_population.csv\"))\n",
    "real_gdp_df = pd.read_csv(os.path.join(csv_path, \"real_GDP.csv\")) #in millions\n",
    "co2_emissions_df = pd.read_excel(os.path.join(excel_path, \"co2_emissions.xlsx\"))\n",
    "tavg_df =  pd.read_csv(os.path.join(csv_path + '/NOA', \"TAVG.csv\"))\n",
    "wind_df =  pd.read_csv(os.path.join(csv_path + '/NOA', \"DYHF.csv\"))\n",
    "tmax_df =  pd.read_csv(os.path.join(csv_path + '/NOA', \"TMAX.csv\"))\n",
    "tmin_df =  pd.read_csv(os.path.join(csv_path + '/NOA', \"TMIN.csv\"))\n",
    "precip_df = pd.read_csv(os.path.join(csv_path + '/NOA', \"PRCP.csv\"))\n",
    "snow_df = pd.read_csv(os.path.join(csv_path + '/NOA', \"SNOW.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'State', '2000', '2001', '2002', '2003', '2004', '2005',\n",
       "       '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014',\n",
       "       '2015', '2016', '2017', '2018', '2019', '2020'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co2_emissions_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2013',\n",
       " '2017',\n",
       " '2019',\n",
       " '2012',\n",
       " '2011',\n",
       " '2015',\n",
       " '2016',\n",
       " '2009',\n",
       " '2008',\n",
       " '2007',\n",
       " '2014',\n",
       " '2018',\n",
       " '2010',\n",
       " 'Unnamed: 0']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use the columns that are in each dataframe after columns with empty values have been dropped. \n",
    "columns_to_evaluate = list(set(vehicle_registration_df.columns).intersection(total_population_df.columns).intersection(total_consuption_df.columns).intersection(real_gdp_df.columns).intersection(industy_gdp_by_state_df.columns).intersection(co2_emissions_df.columns).intersection(tavg_df.columns).intersection(wind_df.columns).intersection(tmax_df.columns).intersection(tmin_df.columns).intersection(precip_df.columns).intersection(snow_df.columns))\n",
    "columns_to_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensure each column we are going to evaluate has the same number of values \n",
    "for col in columns_to_evaluate:\n",
    "    if(not (len(vehicle_registration_df[col]) == len(total_consuption_df[col]) == len(total_population_df[col]) == len(real_gdp_df[col])== len(industy_gdp_by_state_df[col]) == len(co2_emissions_df[col]) == len(tavg_df[col])== len(wind_df[col])== len(tmax_df[col])== len(tmin_df[col])== len(precip_df[col])== len(snow_df[col]))):\n",
    "        print(\"unequal entries for column:\" + col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis\n",
    "\n",
    "#### This section of the notebooks creates a multiple linear regression model for a state's energy consuption.\n",
    "\n",
    "\n",
    "##### In the model summary each variable is represented by the following \n",
    "- x1: Vehicle regisrations\n",
    "- x2: Population\n",
    "- x3: GDP per capita\n",
    "- x4: Industry GDP per capita \n",
    "- x5: C02 emissions\n",
    "- x6: Average tempature\n",
    "- x7: Average wind speed\n",
    "- x8: Maximum tempature\n",
    "- x9: Minimum tempature\n",
    "- x10: Total precipitation\n",
    "- x11: Total snow fall\n",
    "\n",
    "There are some other values in the summary that give us a good indication as to how well our model fits energy consuption such at the r squared value and F statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the data frames and add each value to data_point_pairs array. \n",
    "# The data_point_pairs array will be the \n",
    "# [vehicle registration, population, GDP, Industry GDP, C02 emissions, average tempature, average wind speed, max temperature, min tempature, total precipitation, total snowfall] \n",
    "# value for each year and each state\n",
    "# The total_consumption_vals will be the cooresponding energy consuption value \n",
    "# for the data point pairs item \n",
    "data_point_pairs = []\n",
    "total_consumption_vals = []\n",
    "for col in columns_to_evaluate:\n",
    "    for i in range(0,50):\n",
    "        pair = [vehicle_registration_df.iloc[i][col], total_population_df.iloc[i][col], real_gdp_df.iloc[i][col], industy_gdp_by_state_df.iloc[i][col], co2_emissions_df.iloc[i][col],tavg_df.iloc[i][col],wind_df.iloc[i][col],tmax_df.iloc[i][col],tmin_df.iloc[i][col],precip_df.iloc[i][col],snow_df.iloc[i][col]]\n",
    "        data_point_pairs.append(pair)\n",
    "        \n",
    "        total_consumption_vals.append(total_consuption_df.iloc[i][col]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vehicle registration: 4787219.0\n",
      "population:  738.0\n",
      "GDP:  54748.0\n",
      "Industry GDP:  11241.679347826086\n",
      "C02 emissions:  121.1630059889289\n",
      "Average tempature: 6.774734157214605\n",
      "Average Wind Speed: 2.545909090909091\n",
      "Maximim tempature: 14.073909594750376\n",
      "Mimimum tempature: -0.4421591745467444\n",
      "Total Precipitation: 46.89005639838973\n",
      "Total snowfall: 190.3120019711779\n",
      "total energy consuption: 597975.0\n"
     ]
    }
   ],
   "source": [
    "print(\"vehicle registration:\" , data_point_pairs[0][0])\n",
    "print(\"population: \", data_point_pairs[0][1])\n",
    "print(\"GDP: \", data_point_pairs[0][2])\n",
    "print(\"Industry GDP: \", data_point_pairs[0][3])\n",
    "print(\"C02 emissions: \", data_point_pairs[0][4])\n",
    "print(\"Average tempature:\" ,data_point_pairs[0][5])\n",
    "print(\"Average Wind Speed:\" ,data_point_pairs[0][6])\n",
    "print(\"Maximim tempature:\" ,data_point_pairs[0][7])\n",
    "print(\"Mimimum tempature:\" ,data_point_pairs[0][8])\n",
    "print(\"Total Precipitation:\" ,data_point_pairs[0][9])\n",
    "print(\"Total snowfall:\" ,data_point_pairs[0][10])\n",
    "print(\"total energy consuption:\" ,total_consumption_vals[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted energy consumpion: [853392.04040656]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.933</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.932</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   872.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 05 Dec 2021</td> <th>  Prob (F-statistic):</th>           <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:21:35</td>     <th>  Log-Likelihood:    </th>          <td> -10425.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   700</td>      <th>  AIC:               </th>          <td>2.087e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   689</td>      <th>  BIC:               </th>          <td>2.092e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>      <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>  <td>   -0.0597</td> <td>    0.013</td> <td>   -4.524</td> <td> 0.000</td> <td>   -0.086</td> <td>   -0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>  <td>  205.9536</td> <td>   24.643</td> <td>    8.358</td> <td> 0.000</td> <td>  157.570</td> <td>  254.338</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>  <td>    0.3241</td> <td>    0.399</td> <td>    0.813</td> <td> 0.417</td> <td>   -0.459</td> <td>    1.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>  <td>   -8.2697</td> <td>    2.488</td> <td>   -3.323</td> <td> 0.001</td> <td>  -13.155</td> <td>   -3.384</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>  <td> 9260.8033</td> <td>  432.453</td> <td>   21.415</td> <td> 0.000</td> <td> 8411.720</td> <td> 1.01e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>  <td> 2.281e+05</td> <td> 5.88e+05</td> <td>    0.388</td> <td> 0.698</td> <td>-9.27e+05</td> <td> 1.38e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>  <td>  -1.4e+04</td> <td> 8625.538</td> <td>   -1.623</td> <td> 0.105</td> <td>-3.09e+04</td> <td> 2936.245</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>  <td>-1.177e+05</td> <td> 2.95e+05</td> <td>   -0.399</td> <td> 0.690</td> <td>-6.96e+05</td> <td> 4.61e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>  <td>  -1.1e+05</td> <td> 2.93e+05</td> <td>   -0.375</td> <td> 0.708</td> <td>-6.86e+05</td> <td> 4.66e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th> <td> 2683.0281</td> <td>  925.169</td> <td>    2.900</td> <td> 0.004</td> <td>  866.540</td> <td> 4499.516</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th> <td> -544.6128</td> <td>  404.336</td> <td>   -1.347</td> <td> 0.178</td> <td>-1338.491</td> <td>  249.265</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>706.724</td> <th>  Durbin-Watson:     </th> <td>   1.763</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>75777.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 4.277</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>53.249</td>  <th>  Cond. No.          </th> <td>1.92e+08</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.92e+08. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      y   R-squared (uncentered):                   0.933\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.932\n",
       "Method:                 Least Squares   F-statistic:                              872.5\n",
       "Date:                Sun, 05 Dec 2021   Prob (F-statistic):                        0.00\n",
       "Time:                        18:21:35   Log-Likelihood:                         -10425.\n",
       "No. Observations:                 700   AIC:                                  2.087e+04\n",
       "Df Residuals:                     689   BIC:                                  2.092e+04\n",
       "Df Model:                          11                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1            -0.0597      0.013     -4.524      0.000      -0.086      -0.034\n",
       "x2           205.9536     24.643      8.358      0.000     157.570     254.338\n",
       "x3             0.3241      0.399      0.813      0.417      -0.459       1.107\n",
       "x4            -8.2697      2.488     -3.323      0.001     -13.155      -3.384\n",
       "x5          9260.8033    432.453     21.415      0.000    8411.720    1.01e+04\n",
       "x6          2.281e+05   5.88e+05      0.388      0.698   -9.27e+05    1.38e+06\n",
       "x7           -1.4e+04   8625.538     -1.623      0.105   -3.09e+04    2936.245\n",
       "x8         -1.177e+05   2.95e+05     -0.399      0.690   -6.96e+05    4.61e+05\n",
       "x9           -1.1e+05   2.93e+05     -0.375      0.708   -6.86e+05    4.66e+05\n",
       "x10         2683.0281    925.169      2.900      0.004     866.540    4499.516\n",
       "x11         -544.6128    404.336     -1.347      0.178   -1338.491     249.265\n",
       "==============================================================================\n",
       "Omnibus:                      706.724   Durbin-Watson:                   1.763\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            75777.324\n",
       "Skew:                           4.277   Prob(JB):                         0.00\n",
       "Kurtosis:                      53.249   Cond. No.                     1.92e+08\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.92e+08. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data_point_pairs\n",
    "y = total_consumption_vals\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X,y)\n",
    "\n",
    "#predict energy consuption for vehicle registration = 4610845 , population =699 (10,000), GDP = 55911, \n",
    "#Industry GDP = 9717, C02 emissions = 121, Average tempature = 6.7, Average Wind Speed = 2.5\n",
    "#Maximim tempature = 14.07, Mimimum tempature = -0.44, Total Precipitation = 47, Total snowfall: 190 \n",
    "predictions = lm.predict([[4610845, 699, 55911, 9717, 121, 6.7, 2.5, 14.07, -0.44, 47, 190]])\n",
    "print(\"Predicted energy consumpion:\", predictions )\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "#### This section of the notebooks discusses the results"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
