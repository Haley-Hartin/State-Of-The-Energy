{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebooks explores the relationship between a state's number of vehicle registrations, population, GDP, GDP by industry,  and C02 emissions on it's energy consumption. \n",
    "\n",
    "### The goal is to model a US state's energy consuption by using the data listed above. With this model we can make energy consuption predictions and understand what leads to high energy consuption.\n",
    "\n",
    "### The contents of the notebook include\n",
    "- #### Data Gathering\n",
    "    - read in the dataframes that have been cleaned by data_gathering_and_cleaning notebook\n",
    "- #### Data analysis \n",
    "    - create a multiple linear regression model for energy consuption\n",
    "- #### Conclusion\n",
    "    - Discuss what we discovered and draw conclusions\n",
    "    \n",
    "Note: If there are no files in the Data/cleaned diretory, you will need to run the 'data_gathering_and_cleaning\" notebook to clwan and write out the files to that directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Gathering\n",
    "#### This section of the notebooks reads in the data files and stores them im pandas dataframes.\n",
    "The dataframes frames in this section all have columns of represting years ranging from [1967-2020] and rows for each state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join(os.getcwd(), \"data/cleaned/csv\")\n",
    "excel_path = os.path.join(os.getcwd(), \"data/cleaned/excel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in all datasets here \n",
    "\n",
    "vehicle_registration_df = pd.read_csv(os.path.join(csv_path, \"vehicle_registrations_by_state.csv\"))\n",
    "energy_consumption_per_real_gdp_df = pd.read_csv(os.path.join(csv_path, \"energy_consumption_per_real_gdp.csv\"))\n",
    "current_dollar_gdp_df = pd.read_csv(os.path.join(csv_path, \"Current_dollar_GDP.csv\")) #in millions\n",
    "total_consuption_df = pd.read_csv(os.path.join(csv_path, \"total_consuption.csv\")) #in billion Btu\n",
    "industy_gdp_by_state_df = pd.read_csv(os.path.join(csv_path, \"industy_gdp_by_state.csv\"))\n",
    "total_population_df = pd.read_csv(os.path.join(csv_path, \"total_population.csv\"))\n",
    "real_gdp_df = pd.read_csv(os.path.join(csv_path, \"real_GDP.csv\")) #in millions\n",
    "co2_emissions_df = pd.read_excel(os.path.join(excel_path, \"co2_emissions.xlsx\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " '2015',\n",
       " '2019',\n",
       " '2016',\n",
       " '2013',\n",
       " '2011',\n",
       " '2010',\n",
       " '2007',\n",
       " '2017',\n",
       " '2008',\n",
       " '2012',\n",
       " '2018',\n",
       " '2009',\n",
       " '2014']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use the columns that are in each dataframe after columns with empty values have been dropped. \n",
    "columns_to_evaluate = list(set(vehicle_registration_df.columns).intersection(total_population_df.columns).intersection(total_consuption_df.columns).intersection(real_gdp_df.columns).intersection(industy_gdp_by_state_df.columns).intersection(co2_emissions_df.columns))\n",
    "columns_to_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensure each column we are going to evaluate has the same number of values \n",
    "for col in columns_to_evaluate:\n",
    "    if(not (len(vehicle_registration_df[col]) == len(total_consuption_df[col]) == len(total_population_df[col]) == len(real_gdp_df[col])== len(industy_gdp_by_state_df[col]) == len(co2_emissions_df[col]))):\n",
    "        print(\"unequal entries for column:\" + col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis\n",
    "\n",
    "#### This section of the notebooks creates a multiple linear regression model for a state's energy consuption.\n",
    "\n",
    "We will need to add the climate data.\n",
    "\n",
    "In the model summary, x1 represents vehicle regisration, x2 represents population and x3 represents GDP, x4 represents Industry GDP, x5 represents C02 emissions. There are some other values in the summary that give us a good indication as to how well our model fits energy consuption such at the r squared value and F statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the data frames and add each value to data_point_pairs array. \n",
    "# The data_point_pairs array will be the [vehicle registration, population, GDP, Industry GDP] value for each year and each state\n",
    "# The total_consumption_vals will be the cooresponding energy consuption value \n",
    "# for the [vehicle registration, population, GDP, Industry GDP, C02 emissions] data point\n",
    "data_point_pairs = []\n",
    "total_consumption_vals = []\n",
    "for col in columns_to_evaluate:\n",
    "    for i in range(0,50):\n",
    "        pair = [vehicle_registration_df.iloc[i][col], total_population_df.iloc[i][col], real_gdp_df.iloc[i][col], industy_gdp_by_state_df.iloc[i][col], co2_emissions_df.iloc[i][col]]\n",
    "        data_point_pairs.append(pair)\n",
    "        \n",
    "        total_consumption_vals.append(total_consuption_df.iloc[i][col]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vehicle registration: 10\n",
      "population:  0\n",
      "GDP:  0\n",
      "Industry GDP:  0\n",
      "C02 emissions:  4\n",
      "total energy consuption: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"vehicle registration:\" , data_point_pairs[0][0])\n",
    "print(\"population: \", data_point_pairs[0][1])\n",
    "print(\"GDP: \", data_point_pairs[0][2])\n",
    "print(\"Industry GDP: \", data_point_pairs[0][3])\n",
    "print(\"C02 emissions: \", data_point_pairs[0][4])\n",
    "print(\"total energy consuption:\" ,total_consumption_vals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted energy consumpion for \n",
      "vehicle registration = 4610845 , population = 699 (10,000), GDP = 55911, Industry GDP = 9717, C02 emissions = 121 \n",
      " [975165.04327189]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.930</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.930</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   1850.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 16 Nov 2021</td> <th>  Prob (F-statistic):</th>           <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:17:10</td>     <th>  Log-Likelihood:    </th>          <td> -10440.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   700</td>      <th>  AIC:               </th>          <td>2.089e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   695</td>      <th>  BIC:               </th>          <td>2.091e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td>   -0.0548</td> <td>    0.013</td> <td>   -4.146</td> <td> 0.000</td> <td>   -0.081</td> <td>   -0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th> <td>  210.7417</td> <td>   23.754</td> <td>    8.872</td> <td> 0.000</td> <td>  164.105</td> <td>  257.379</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th> <td>    0.3225</td> <td>    0.387</td> <td>    0.834</td> <td> 0.405</td> <td>   -0.437</td> <td>    1.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th> <td>   -8.3741</td> <td>    2.479</td> <td>   -3.378</td> <td> 0.001</td> <td>  -13.241</td> <td>   -3.507</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th> <td> 9335.0498</td> <td>  427.329</td> <td>   21.845</td> <td> 0.000</td> <td> 8496.038</td> <td> 1.02e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>684.076</td> <th>  Durbin-Watson:     </th> <td>   1.746</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>67045.337</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 4.072</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>50.248</td>  <th>  Cond. No.          </th> <td>1.12e+05</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.12e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      y   R-squared (uncentered):                   0.930\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.930\n",
       "Method:                 Least Squares   F-statistic:                              1850.\n",
       "Date:                Tue, 16 Nov 2021   Prob (F-statistic):                        0.00\n",
       "Time:                        12:17:10   Log-Likelihood:                         -10440.\n",
       "No. Observations:                 700   AIC:                                  2.089e+04\n",
       "Df Residuals:                     695   BIC:                                  2.091e+04\n",
       "Df Model:                           5                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1            -0.0548      0.013     -4.146      0.000      -0.081      -0.029\n",
       "x2           210.7417     23.754      8.872      0.000     164.105     257.379\n",
       "x3             0.3225      0.387      0.834      0.405      -0.437       1.082\n",
       "x4            -8.3741      2.479     -3.378      0.001     -13.241      -3.507\n",
       "x5          9335.0498    427.329     21.845      0.000    8496.038    1.02e+04\n",
       "==============================================================================\n",
       "Omnibus:                      684.076   Durbin-Watson:                   1.746\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            67045.337\n",
       "Skew:                           4.072   Prob(JB):                         0.00\n",
       "Kurtosis:                      50.248   Cond. No.                     1.12e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.12e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A potential library we can use for regression analysis \n",
    "# normalize population\n",
    "\n",
    "X = data_point_pairs\n",
    "y = total_consumption_vals\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X,y)\n",
    "\n",
    "#predict energy consuption for vehicle registration = 4610845 , population =699 (10,000), GDP = 55911, Industry GDP = 9717, C02 emissions = 121\n",
    "predictions = lm.predict([[4610845, 699, 55911, 9717, 121]])\n",
    "print(\"Predicted energy consumpion for \\nvehicle registration = 4610845 , population = 699 (10,000), GDP = 55911, Industry GDP = 9717, C02 emissions = 121 \\n\", predictions )\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "#### This section of the notebooks discusses the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
